import numpy as np
import re
from typing import Dict, Tuple, Any

WEIGHT_THRESHOLD = 1.5e-3    # é‡ã¿ç”¨é–¾å€¤ï¼ˆæ¨å¥¨: 1e-3ï¼‰
BIAS_THRESHOLD = 1e-6     # ãƒã‚¤ã‚¢ã‚¹ç”¨é–¾å€¤ï¼ˆæ¨å¥¨: 1e-4ï¼‰

class ModelParameterProcessor:
    def __init__(self, weight_threshold: float = WEIGHT_THRESHOLD, bias_threshold: float = BIAS_THRESHOLD):
        self.weight_threshold = weight_threshold
        self.bias_threshold = bias_threshold
        self.arrays = {}
    
    @property 
    def threshold(self):
        """å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚"""
        return self.weight_threshold
        
    def get_threshold_for_param(self, param_name: str) -> float:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸé–¾å€¤ã‚’è¿”ã™"""
        if 'bias' in param_name:
            return self.bias_threshold
        else:
            return self.weight_threshold
    
    def parse_model_parameters(self, file_path: str) -> Dict[str, np.ndarray]:
        """model_parameters.hãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’æŠ½å‡º"""
        print(f"ğŸ“– {file_path}ã‚’è§£æä¸­...")
        
        with open(file_path, 'r') as f:
            content = f.read()
        
        # floaté…åˆ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒ
        pattern = r'float\s+(\w+)\[\]\s*=\s*\{([^}]+)\};'
        matches = re.findall(pattern, content)
        
        arrays = {}
        for name, values_str in matches:
            # æ•°å€¤ã‚’æŠ½å‡ºã—ã¦é…åˆ—ã«å¤‰æ›
            numbers = re.findall(r'-?[\d.]+(?:[eE][-+]?\d+)?', values_str)
            values = [float(num_str) for num_str in numbers]
            arrays[name] = np.array(values, dtype=np.float32)
            print(f"  âœ“ {name}: {len(values)}å€‹ã®è¦ç´ ")
        
        self.arrays = arrays
        return arrays
    
    def detect_network_structure(self) -> list:
        """å®Ÿéš›ã®é…åˆ—ã‚µã‚¤ã‚ºã‹ã‚‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’è‡ªå‹•æ¤œå‡º"""
        print("\nğŸ” ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’è‡ªå‹•æ¤œå‡ºä¸­...")
        
        # å„é…åˆ—ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèª
        sizes = {name: len(array) for name, array in self.arrays.items()}
        print(f"   é…åˆ—ã‚µã‚¤ã‚º: {sizes}")
        
        # ãƒã‚¤ã‚¢ã‚¹ã‚µã‚¤ã‚ºã‹ã‚‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚µã‚¤ã‚ºã‚’æ¨å®š
        bias_sizes = {name: size for name, size in sizes.items() if 'bias' in name}
        print(f"   ãƒã‚¤ã‚¢ã‚¹ã‚µã‚¤ã‚º: {bias_sizes}")
        
        # weighté…åˆ—ã®ã‚µã‚¤ã‚ºã‹ã‚‰æ§‹é€ ã‚’æ¨å®š
        network_structure = []
        
        # Layer 1ã®æ¨å®š
        if 'weight_1' in sizes and 'bias_1' in sizes:
            weight1_size = sizes['weight_1']
            bias1_size = sizes['bias_1']
            input_size = 3  # RGBå…¥åŠ›
            output_size = bias1_size
            
            if weight1_size == input_size * output_size:
                network_structure.append(('weight_1', input_size, output_size))
                network_structure.append(('bias_1', output_size, 1))
                print(f"   Layer 1: å…¥åŠ›{input_size} â†’ éš ã‚Œå±¤{output_size}")
            else:
                print(f"   âš ï¸ Layer 1ã®ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“: {weight1_size} â‰  {input_size}Ã—{output_size}")
        
        # Layer 2ã®æ¨å®š
        if 'weight_2' in sizes and 'bias_2' in sizes:
            weight2_size = sizes['weight_2']
            bias2_size = sizes['bias_2']
            input_size = bias1_size  # å‰å±¤ã®å‡ºåŠ›ã‚µã‚¤ã‚º
            output_size = bias2_size
            
            if weight2_size == input_size * output_size:
                network_structure.append(('weight_2', input_size, output_size))
                network_structure.append(('bias_2', output_size, 1))
                print(f"   Layer 2: éš ã‚Œå±¤{input_size} â†’ éš ã‚Œå±¤{output_size}")
            else:
                print(f"   âš ï¸ Layer 2ã®ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“: {weight2_size} â‰  {input_size}Ã—{output_size}")
        
        # Layer 3ã®æ¨å®š
        if 'weight_3' in sizes and 'bias_3' in sizes:
            weight3_size = sizes['weight_3']
            bias3_size = sizes['bias_3']
            input_size = bias2_size  # å‰å±¤ã®å‡ºåŠ›ã‚µã‚¤ã‚º
            output_size = bias3_size
            
            if weight3_size == input_size * output_size:
                network_structure.append(('weight_3', input_size, output_size))
                network_structure.append(('bias_3', output_size, 1))
                print(f"   Layer 3: éš ã‚Œå±¤{input_size} â†’ å‡ºåŠ›{output_size}")
            else:
                print(f"   âš ï¸ Layer 3ã®ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“: {weight3_size} â‰  {input_size}Ã—{output_size}")
        
        print(f"   æ¤œå‡ºã•ã‚ŒãŸæ§‹é€ : {network_structure}")
        return network_structure
    
    def prune_weights(self, weights: np.ndarray, name: str = "unknown") -> Tuple[np.ndarray, float]:
        """é–¾å€¤ä»¥ä¸‹ã®é‡ã¿ã‚’0ã«ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè©³ç´°ãƒ‡ãƒãƒƒã‚°ä»˜ãï¼‰"""
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸé–¾å€¤ã‚’å–å¾—
        threshold = self.get_threshold_for_param(name)
        
        print(f"\nğŸ”§ {name} ã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†:")
        print(f"   ä½¿ç”¨é–¾å€¤: {threshold} ({'ãƒã‚¤ã‚¢ã‚¹ç”¨' if 'bias' in name else 'é‡ã¿ç”¨'})")
        
        # å…ƒã®çµ±è¨ˆ
        original_weights = weights.copy()
        original_nonzero = np.count_nonzero(weights)
        original_abs_below_threshold = np.sum(np.abs(weights) < threshold)
        original_abs_above_threshold = np.sum(np.abs(weights) >= threshold)
        
        print(f"   å…ƒã®éã‚¼ãƒ­è¦ç´ : {original_nonzero}/{len(weights)} ({original_nonzero/len(weights)*100:.1f}%)")
        print(f"   å…ƒã®é–¾å€¤ä»¥ä¸‹è¦ç´ : {original_abs_below_threshold} ({original_abs_below_threshold/len(weights)*100:.1f}%)")
        print(f"   å…ƒã®é–¾å€¤ä»¥ä¸Šè¦ç´ : {original_abs_above_threshold} ({original_abs_above_threshold/len(weights)*100:.1f}%)")
        
        # åˆ†å¸ƒåˆ†æï¼ˆé–¾å€¤ã‚’æ¸¡ã™ï¼‰
        distribution = self.analyze_weight_distribution(weights, name, threshold)
        
        # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        pruned_weights = weights.copy()
        mask = np.abs(pruned_weights) < threshold
        pruned_count = np.sum(mask)
        pruned_weights[mask] = 0
        
        # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®çµ±è¨ˆ
        final_nonzero = np.count_nonzero(pruned_weights)
        
        print(f"\n   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œçµæœ:")
        print(f"   ã‚¼ãƒ­ã«ã—ãŸè¦ç´ æ•°: {pruned_count}")
        print(f"   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œéã‚¼ãƒ­è¦ç´ : {final_nonzero}/{len(weights)} ({final_nonzero/len(weights)*100:.1f}%)")
        
        # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ç‡ã®è¨ˆç®—
        pruning_ratio = pruned_count / len(weights) * 100
        compression_ratio = (original_nonzero - final_nonzero) / len(weights) * 100
        
        print(f"   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ç‡: {pruning_ratio:.2f}% (ã‚¼ãƒ­ã«ã—ãŸè¦ç´ /å…¨è¦ç´ )")
        print(f"   åœ§ç¸®ç‡: {compression_ratio:.2f}% (æ¸›å°‘ã—ãŸéã‚¼ãƒ­è¦ç´ /å…¨è¦ç´ )")
        
        # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå€¤ã®åˆ†æ
        if pruned_count > 0:
            pruned_values = original_weights[mask]
            pruned_abs_values = np.abs(pruned_values)
            print(f"   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå€¤ã®ç¯„å›²: {np.min(pruned_abs_values):.8f} ~ {np.max(pruned_abs_values):.8f}")
            print(f"   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå€¤ã®å¹³å‡: {np.mean(pruned_abs_values):.8f}")
        else:
            print(f"   âš ï¸ ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸè¦ç´ ãŒã‚ã‚Šã¾ã›ã‚“ï¼")
            print(f"   â†’ å…¨ã¦ã®è¦ç´ ãŒé–¾å€¤({threshold})ä»¥ä¸Šã§ã™")
        
        return pruned_weights, pruning_ratio
    
    def analyze_weight_distribution(self, weights: np.ndarray, name: str, threshold: float = None) -> Dict[str, Any]:
        """é‡ã¿ã®åˆ†å¸ƒã‚’åˆ†æ"""
        if threshold is None:
            threshold = self.get_threshold_for_param(name)
            
        abs_weights = np.abs(weights)
        
        stats = {
            'min': float(np.min(abs_weights)),
            'max': float(np.max(abs_weights)),
            'mean': float(np.mean(abs_weights)),
            'median': float(np.median(abs_weights)),
            'std': float(np.std(abs_weights)),
            'below_threshold': int(np.sum(abs_weights < threshold)),
            'above_threshold': int(np.sum(abs_weights >= threshold)),
            'zeros': int(np.sum(abs_weights == 0)),
            'total_elements': len(weights)
        }
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«æƒ…å ±
        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
        for p in percentiles:
            stats[f'p{p}'] = float(np.percentile(abs_weights, p))
        
        print(f"\nğŸ” {name} ã®é‡ã¿åˆ†å¸ƒåˆ†æ:")
        print(f"   è¦ç´ æ•°: {stats['total_elements']}")
        print(f"   ã‚¼ãƒ­è¦ç´ : {stats['zeros']} ({stats['zeros']/stats['total_elements']*100:.1f}%)")
        print(f"   é–¾å€¤({threshold})ä»¥ä¸‹: {stats['below_threshold']} ({stats['below_threshold']/stats['total_elements']*100:.1f}%)")
        print(f"   é–¾å€¤ä»¥ä¸Š: {stats['above_threshold']} ({stats['above_threshold']/stats['total_elements']*100:.1f}%)")
        print(f"   æœ€å°å€¤: {stats['min']:.8f}")
        print(f"   æœ€å¤§å€¤: {stats['max']:.8f}")
        print(f"   å¹³å‡å€¤: {stats['mean']:.8f}")
        print(f"   ä¸­å¤®å€¤: {stats['median']:.8f}")
        print(f"   æ¨™æº–åå·®: {stats['std']:.8f}")
        
        # é–¾å€¤å‘¨è¾ºã®å€¤ã‚’ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        near_threshold = abs_weights[(abs_weights > threshold/10) & (abs_weights < threshold*10)]
        if len(near_threshold) > 0:
            print(f"   é–¾å€¤å‘¨è¾ºã®å€¤ã‚µãƒ³ãƒ—ãƒ«: {sorted(near_threshold)[:10]}")
        
        return stats
    
    def dense_to_csr(self, matrix: np.ndarray) -> Dict[str, Any]:
        """å¯†è¡Œåˆ—ã‚’CSRå½¢å¼ã«å¤‰æ›"""
        if len(matrix.shape) == 1:
            # 1æ¬¡å…ƒé…åˆ—ï¼ˆãƒã‚¤ã‚¢ã‚¹ï¼‰ã®å ´åˆ
            nonzero_indices = np.nonzero(matrix)[0]
            values = matrix[nonzero_indices]
            
            return {
                'values': values.astype(np.float32),
                'indices': nonzero_indices.astype(np.int32),
                'indptr': np.array([0, len(nonzero_indices)], dtype=np.int32),
                'shape': matrix.shape,
                'nnz': len(values),
                'is_1d': True
            }
        else:
            # 2æ¬¡å…ƒé…åˆ—ï¼ˆé‡ã¿ï¼‰ã®å ´åˆ
            rows, cols = np.nonzero(matrix)
            values = matrix[rows, cols]
            
            # è¡Œãƒã‚¤ãƒ³ã‚¿ã‚’ä½œæˆ
            indptr = np.zeros(matrix.shape[0] + 1, dtype=np.int32)
            for row in rows:
                indptr[row + 1] += 1
            indptr = np.cumsum(indptr)
            
            return {
                'values': values.astype(np.float32),
                'indices': cols.astype(np.int32),
                'indptr': indptr,
                'shape': matrix.shape,
                'nnz': len(values),
                'is_1d': False
            }
    
    def reshape_weight_to_matrix(self, weight_array: np.ndarray, input_size: int, output_size: int) -> np.ndarray:
        """1æ¬¡å…ƒã®é‡ã¿é…åˆ—ã‚’2æ¬¡å…ƒè¡Œåˆ—ã«å¤‰å½¢"""
        expected_size = input_size * output_size
        actual_size = len(weight_array)
        
        if actual_size != expected_size:
            raise ValueError(f"é…åˆ—ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“: å®Ÿéš›={actual_size}, æœŸå¾…={expected_size} ({input_size}Ã—{output_size})")
        
        return weight_array.reshape(output_size, input_size)
    
    def process_all_layers(self) -> Dict[str, Dict[str, Any]]:
        """å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡¦ç†ã‚’å®Ÿè¡Œ"""
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’è‡ªå‹•æ¤œå‡º
        network_structure = self.detect_network_structure()
        
        if not network_structure:
            raise ValueError("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        processed_layers = {}
        total_original = 0
        total_compressed = 0
        
        print(f"\nğŸ”§ é‡ã¿ç”¨é–¾å€¤: {self.weight_threshold}")
        print(f"ğŸ”§ ãƒã‚¤ã‚¢ã‚¹ç”¨é–¾å€¤: {self.bias_threshold}")
        print(f"ğŸ”§ é‡ã¿é–¾å€¤ã®ç§‘å­¦è¨˜æ³•: {self.weight_threshold:.2e}")
        print(f"ğŸ”§ ãƒã‚¤ã‚¢ã‚¹é–¾å€¤ã®ç§‘å­¦è¨˜æ³•: {self.bias_threshold:.2e}")
        print("=" * 80)
        
        for param_name, input_size, output_size in network_structure:
            if param_name not in self.arrays:
                print(f"âš ï¸  {param_name}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            original_array = self.arrays[param_name]
            total_original += len(original_array)
            
            print(f"\nğŸ“Š {param_name} ã®å‡¦ç†é–‹å§‹:")
            print(f"   é…åˆ—ã‚µã‚¤ã‚º: {len(original_array)}")
            print(f"   å½¢çŠ¶æƒ…å ±: å…¥åŠ›{input_size} â†’ å‡ºåŠ›{output_size}")
            
            # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãï¼‰
            pruned_array, pruning_ratio = self.prune_weights(original_array, param_name)
            
            # ãƒã‚¤ã‚¢ã‚¹ã¯1æ¬¡å…ƒã®ã¾ã¾ã€é‡ã¿ã¯2æ¬¡å…ƒã«å¤‰å½¢
            if 'weight' in param_name:
                matrix = self.reshape_weight_to_matrix(pruned_array, input_size, output_size)
            else:
                matrix = pruned_array
            
            # CSRå½¢å¼ã«å¤‰æ›
            csr_data = self.dense_to_csr(matrix)
            
            # åœ§ç¸®ç‡è¨ˆç®—
            compression_ratio = (1 - csr_data['nnz'] / len(original_array)) * 100
            total_compressed += csr_data['nnz']
            
            # çµæœã‚’ä¿å­˜
            processed_layers[param_name] = {
                'original_size': len(original_array),
                'csr_data': csr_data,
                'pruning_ratio': pruning_ratio,
                'compression_ratio': compression_ratio,
                'input_size': input_size,
                'output_size': output_size
            }
            
            print(f"\nğŸ“ˆ {param_name} ã®æœ€çµ‚çµæœ:")
            print(f"   å…ƒã‚µã‚¤ã‚º: {len(original_array)} â†’ éã‚¼ãƒ­: {csr_data['nnz']}")
            print(f"   ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ç‡: {pruning_ratio:.2f}%")
            print(f"   CSRåœ§ç¸®ç‡: {compression_ratio:.2f}%")
        
        print("\n" + "=" * 80)
        overall_compression = (1 - total_compressed / total_original) * 100
        print(f"ğŸ¯ å…¨ä½“çµ±è¨ˆ:")
        print(f"   å…ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_original}")
        print(f"   åœ§ç¸®å¾Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_compressed}")
        print(f"   å…¨ä½“åœ§ç¸®ç‡: {overall_compression:.2f}%")
        print(f"   æ¨å®šãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {(total_original - total_compressed) * 4}ãƒã‚¤ãƒˆ")
        
        return processed_layers
    
    def generate_csr_header(self, processed_layers: Dict[str, Dict[str, Any]]) -> str:
        """CSRå½¢å¼ã®ãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        print(f"\nğŸ“ CSRãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
        
        header_content = f"""// CSRå½¢å¼ã§åœ§ç¸®ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
// é‡ã¿ç”¨ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°é–¾å€¤: {self.weight_threshold}
// ãƒã‚¤ã‚¢ã‚¹ç”¨ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°é–¾å€¤: {self.bias_threshold}
// è‡ªå‹•ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ« - æ‰‹å‹•ç·¨é›†ç¦æ­¢
#ifndef MODEL_PARAMETERS_CSR_H
#define MODEL_PARAMETERS_CSR_H

#include <stdint.h>
#ifdef ARDUINO
#include <avr/pgmspace.h>
#define CSR_PROGMEM PROGMEM
#else
#define CSR_PROGMEM
#endif

"""

        # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        for param_name, layer_info in processed_layers.items():
            csr = layer_info['csr_data']
            
            header_content += f"""
// {param_name} - CSRå½¢å¼
// å…ƒã‚µã‚¤ã‚º: {layer_info['original_size']}, éã‚¼ãƒ­è¦ç´ : {csr['nnz']}, åœ§ç¸®ç‡: {layer_info['compression_ratio']:.1f}%
const float {param_name}_values[] CSR_PROGMEM = {{"""
            
            # å€¤ã®é…åˆ—
            for i, val in enumerate(csr['values']):
                if i % 8 == 0:
                    header_content += "\n    "
                header_content += f"{val:.8f}f"
                if i < len(csr['values']) - 1:
                    header_content += ", "
            header_content += "\n};\n"
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é…åˆ—
            header_content += f"""
const int32_t {param_name}_indices[] CSR_PROGMEM = {{"""
            for i, idx in enumerate(csr['indices']):
                if i % 12 == 0:
                    header_content += "\n    "
                header_content += f"{idx}"
                if i < len(csr['indices']) - 1:
                    header_content += ", "
            header_content += "\n};\n"
            
            # è¡Œãƒã‚¤ãƒ³ã‚¿é…åˆ—ï¼ˆ2æ¬¡å…ƒã®å ´åˆã®ã¿ï¼‰
            if not csr['is_1d']:
                header_content += f"""
const int32_t {param_name}_indptr[] CSR_PROGMEM = {{"""
                for i, ptr in enumerate(csr['indptr']):
                    if i % 12 == 0:
                        header_content += "\n    "
                    header_content += f"{ptr}"
                    if i < len(csr['indptr']) - 1:
                        header_content += ", "
                header_content += "\n};\n"

        # æ§‹é€ ä½“å®šç¾©ã‚’è¿½åŠ 
        header_content += """
// CSRå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
typedef struct {
    const float* values;
    const int32_t* indices;
    const int32_t* indptr;
    int32_t nnz;
    int32_t rows;
    int32_t cols;
} csr_matrix_t;

typedef struct {
    const float* values;
    const int32_t* indices;
    int32_t nnz;
    int32_t size;
} csr_vector_t;

"""

        # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ§‹é€ ä½“ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
        for param_name, layer_info in processed_layers.items():
            csr = layer_info['csr_data']
            
            if csr['is_1d']:
                header_content += f"""
const csr_vector_t {param_name}_csr = {{
    {param_name}_values,
    {param_name}_indices,
    {csr['nnz']},
    {csr['shape'][0]}
}};
"""
            else:
                header_content += f"""
const csr_matrix_t {param_name}_csr = {{
    {param_name}_values,
    {param_name}_indices,
    {param_name}_indptr,
    {csr['nnz']},
    {csr['shape'][0]},
    {csr['shape'][1]}
}};
"""

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®è¿½åŠ 
        header_content += """
// CSRå½¢å¼ã‹ã‚‰å€¤ã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
#ifdef ARDUINO
#define READ_PROGMEM_FLOAT(addr) pgm_read_float(addr)
#define READ_PROGMEM_DWORD(addr) pgm_read_dword(addr)
#else
#define READ_PROGMEM_FLOAT(addr) (*(addr))
#define READ_PROGMEM_DWORD(addr) (*(addr))
#endif

// CSRè¡Œåˆ—ã‹ã‚‰å€¤ã‚’å–å¾—
static inline float get_csr_weight(const csr_matrix_t* csr, int row, int col) {
    int32_t start = READ_PROGMEM_DWORD(&csr->indptr[row]);
    int32_t end = READ_PROGMEM_DWORD(&csr->indptr[row + 1]);
    
    for (int32_t i = start; i < end; i++) {
        if (READ_PROGMEM_DWORD(&csr->indices[i]) == col) {
            return READ_PROGMEM_FLOAT(&csr->values[i]);
        }
    }
    return 0.0f;  // ã‚¹ãƒ‘ãƒ¼ã‚¹è¦ç´ ã¯0
}

// CSRãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰å€¤ã‚’å–å¾—
static inline float get_csr_bias(const csr_vector_t* csr, int index) {
    for (int32_t i = 0; i < csr->nnz; i++) {
        if (READ_PROGMEM_DWORD(&csr->indices[i]) == index) {
            return READ_PROGMEM_FLOAT(&csr->values[i]);
        }
    }
    return 0.0f;  // ã‚¹ãƒ‘ãƒ¼ã‚¹è¦ç´ ã¯0
}

#endif // MODEL_PARAMETERS_CSR_H
"""
        
        return header_content

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ model_parameters.h â†’ model_parameters_csr.h å¤‰æ›å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"âš™ï¸ è¨­å®šã•ã‚ŒãŸé–¾å€¤: é‡ã¿={WEIGHT_THRESHOLD:.0e}, ãƒã‚¤ã‚¢ã‚¹={BIAS_THRESHOLD:.0e}")
    
    # é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ã§ç•°ãªã‚‹é–¾å€¤ãƒ†ã‚¹ãƒˆ
    test_configs = [
        {"weight": 1e-4, "bias": 1e-5, "description": "é‡ã¿1e-4, ãƒã‚¤ã‚¢ã‚¹1e-5"},
        {"weight": 1e-3, "bias": 1e-4, "description": "é‡ã¿1e-3, ãƒã‚¤ã‚¢ã‚¹1e-4"},
        {"weight": 1e-2, "bias": 1e-3, "description": "é‡ã¿1e-2, ãƒã‚¤ã‚¢ã‚¹1e-3"},
        {"weight": 1e-1, "bias": 1e-2, "description": "é‡ã¿1e-1, ãƒã‚¤ã‚¢ã‚¹1e-2"},
    ]
    
    print(f"\nğŸ§ª ç•°ãªã‚‹é–¾å€¤ã§ã®åœ§ç¸®ç‡ãƒ†ã‚¹ãƒˆ:")
    
    for config in test_configs:
        print(f"\n{'='*60}")
        print(f"ğŸ” {config['description']}:")
        print(f"{'='*60}")
        
        processor = ModelParameterProcessor(
            weight_threshold=config["weight"], 
            bias_threshold=config["bias"]
        )
        
        try:
            arrays = processor.parse_model_parameters("model_parameters.h")
            
            if not arrays:
                print("âŒ é…åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            # ç°¡æ˜“çµ±è¨ˆè¡¨ç¤º
            total_prunable = 0
            for name, array in arrays.items():
                threshold = processor.get_threshold_for_param(name)
                abs_array = np.abs(array)
                below_threshold = np.sum(abs_array < threshold)
                total_prunable += below_threshold
                print(f"   {name}: {below_threshold}/{len(array)}è¦ç´ ãŒé–¾å€¤({threshold:.0e})ä»¥ä¸‹ ({below_threshold/len(array)*100:.1f}%)")
            
            total_elements = sum(len(array) for array in arrays.values())
            print(f"   ğŸ“Š å…¨ä½“: {total_prunable}/{total_elements}è¦ç´ ãŒãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ ({total_prunable/total_elements*100:.1f}%)")
            
        except FileNotFoundError:
            print("âŒ ã‚¨ãƒ©ãƒ¼: model_parameters.hãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return
    
    # å®Ÿéš›ã®å¤‰æ›å‡¦ç†ï¼ˆè¨­å®šã•ã‚ŒãŸé–¾å€¤ã‚’ä½¿ç”¨ï¼‰
    print(f"\n{'='*60}")
    print(f"ğŸš€ å®Ÿéš›ã®å¤‰æ›å‡¦ç† (é‡ã¿: {WEIGHT_THRESHOLD:.0e}, ãƒã‚¤ã‚¢ã‚¹: {BIAS_THRESHOLD:.0e}):")
    print(f"{'='*60}")
    
    processor = ModelParameterProcessor(weight_threshold=WEIGHT_THRESHOLD, bias_threshold=BIAS_THRESHOLD)
    
    try:
        # model_parameters.hã‚’è§£æ
        processor.parse_model_parameters("model_parameters.h")
        
        # å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å‡¦ç†
        processed_layers = processor.process_all_layers()
        
        # CSRãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        header_content = processor.generate_csr_header(processed_layers)
        with open("model_parameters_csr.h", "w") as f:
            f.write(header_content)
        
        print(f"\nâœ… å¤‰æ›å®Œäº†ï¼")
        print(f"   ğŸ“„ model_parameters_csr.h ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
        print(f"   ğŸ¯ å…¨ä½“åœ§ç¸®ç‡: {(1 - sum(layer['csr_data']['nnz'] for layer in processed_layers.values()) / sum(layer['original_size'] for layer in processed_layers.values())) * 100:.1f}%")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()